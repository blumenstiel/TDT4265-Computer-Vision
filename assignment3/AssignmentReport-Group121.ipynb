{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report\n",
    "\n",
    "Group 121 – Etienne Gaucher, Benedikt Blumenstiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "## Task 1a)\n",
    "With zero-padding:\n",
    "\n",
    " 2 | -1 | 11 | -2 | -13\n",
    "---|---|---|---|---\n",
    " 10 | -4 | 8 | 2 | -18\n",
    " 14 | -1 | -6 | 6 | -9\n",
    "\n",
    "## Task 1b)\n",
    "The __\"Max Pooling\"__ Layer reduce the sensitivity to translationial variations due to the combination of multiple pixels.\n",
    "\n",
    "## Task 1c)\n",
    "As the kernel size is 5x5 the padding should be __2__ on each side to get the same shape.\n",
    "\n",
    "## Task 1d)\n",
    "As the size is reduced by 8 (512 - 504) in each dimension the kernel has a shape of __9 x 9__ (8 +1 centered pixel).\n",
    "\n",
    "## Task 1e)\n",
    "Based in the input shape of 504 x 504 the output shape of the pooling layer is __252 x 252__ as the stride of 2 divide the\n",
    "size in each dimension by 2 (504 / 2 = 252).\n",
    "\n",
    "## Task 1f)\n",
    "THe output shape of the second conv layer is __250 x 250__.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Task 1g)\n",
    "\\begin{align*}\n",
    "number\\ of\\ parameters =\\ & number\\ of\\ weights + number\\ of\\ biases\\\\\n",
    "number\\ of\\ parameters =\\ & 3 ∗ 5 ∗ 5 ∗ 32 + 32 +\\\\\n",
    "& 5 ∗ 5 ∗ 32 ∗ 64 + 64 +\\\\\n",
    "& 5 ∗ 5 ∗ 64 ∗ 128 + 128 +\\\\\n",
    "& 2048 ∗ 64 + 64 +\\\\\n",
    "& 64 ∗ 10 + 10\\\\\n",
    "=\\ & 390410\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2a)\n",
    "\n",
    "![](task2a_loss_plot.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2b)\n",
    "\n",
    "The final training accuracy is 0.75.\n",
    "\n",
    "The final validation accuracy is 0.698.\n",
    "\n",
    "The final test accuracy is 0.698."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3a)\n",
    "\n",
    "\n",
    "First model:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.1\n",
    "\n",
    "Optimizer = SGD, without momentum\n",
    "\n",
    "Regularization = no\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = RandomHorizontalFlip(p=0.3)\n",
    "\n",
    "---\n",
    "\n",
    "Second model:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "1 | BatchNorm2D | - | -\n",
    "1 | Dropout (p=0.2) | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "2 | BatchNorm2D | - | -\n",
    "2 | Dropout (p=0.2) | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "3 | BatchNorm2D | - | -\n",
    "3 | Dropout (p=0.2) | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "4 | BatchNorm1D | - | -\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.05\n",
    "\n",
    "Optimizer = SGD, without momentum\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = no\n",
    "\n",
    "\n",
    "## Task 3b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model| Train loss | Training accuracy | Validation accuracy | Test accuracy\n",
    "-|-|--|-- | --\n",
    "1 | 0.3188 | 0.8946 | 0.7911 | 0.7866\n",
    "2 | 0.2772 | 0.9036 | 0.7571 | 0.7567\n",
    "\n",
    "Loss and accurancy of Model 1:\n",
    "![](task3b_best_model.png)\n",
    "\n",
    "## Task 3c)\n",
    "\n",
    "After having tried all the different tricks to improve our model, we notice batch normalization, data augmentation and\n",
    "dropout are the most useful and effective methods. The network is more efficient with batch\n",
    "normalization since each layer learns independently of the other layers. With data augmentation, the neural network\n",
    "generalizes better because we train our model on different pictures, the model doesn't learn with the same pictures.\n",
    "Similarly, dropout forces the network to more generalize by \"cuting\" connections. After testing different dropout values,\n",
    "the model generalize best with 0.2.\n",
    "\n",
    "Reducing the filter sizes and the number of filter don't work. The activation function nn.Tanh doesn't improve the model.\n",
    "We also tested the Adam Optimizer, but the model did not improve. Compared with Task 4a, Adam Optimizer is maybe better\n",
    "for fine tuning a model or training Dense (fully connected) layers.\n",
    "\n",
    "## Task 3d)\n",
    "\n",
    "Comparision of Baseline Model (Task 2) to Model 1 of Task 3a (Batch Normalization, increased number of\n",
    "hidden neurons and Data Augmentation)\n",
    "![](task3d_compare_best_model.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)\n",
    "\n",
    "\n",
    "We improve our models to reach an accuracy of at least 80% on the test set within 10 epochs by combining the methods of\n",
    "both models: dropout, data augmentation as well as adding .\n",
    "\n",
    "TODO: Model reaches only 78% in test accuracy!!!\n",
    "\n",
    "The model is:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "1 | BatchNorm2D | - | -\n",
    "1 | Dropout (p=0.2) | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "2 | BatchNorm2D | - | -\n",
    "2 | Dropout (p=0.2) | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "3 | BatchNorm2D | - | -\n",
    "3 | Dropout (p=0.2) | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "4 | BatchNorm1D | - | -\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.1\n",
    "\n",
    "Optimizer = SGD, momentum = 0.7\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = RandomHorizontalFlip(p=0.3)\n",
    "\n",
    "We get a test accuracy of 78.01%.\n",
    "\n",
    "![](task3e_final_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3f)\n",
    "\n",
    "There are no signs of overfitting or underfitting, the validation accuracy increases during the training and is stable just at the end of the training. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Task 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4a)\n",
    "![](task4a_transfer_learning.png)\n",
    "\n",
    "The model reached a final values:\n",
    "* Training loss: 0.1321\n",
    "* Training accuracy: 0.9561\n",
    "* Validation accuracy: 0.8901\n",
    "* Test accuracy: 0.8928\n",
    "\n",
    "\n",
    "\n",
    "Following the advice we choose this hyperparameters:\n",
    "* Adam Optimizer\n",
    "* batch_size = 32\n",
    "* learning_rate = 5e-4\n",
    "* epochs = 5\n",
    "* early_stop_count = 4\n",
    "+ data augmentation = RandomHorizontalFlip(p=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](task4b_zebra_first_weights.png)\n",
    "![](task4b_zebra_first_activation.png)\n",
    "\n",
    "The ﬁlter weights (top row) and the activation to the corresponding ﬁlter (bottom row) of the ﬁrst\n",
    "convolutional layer in ResNet18 with indices [14, 26, 32, 49, 52].\n",
    "\n",
    "The brighter a area the higher the activation of the filter. The different filter extract different information from the\n",
    "image. For example, the selected filters are detecting the outline of the zebra (14th filter), edges (26th filter) and\n",
    "different colors (49th filter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Task 4c)\n",
    "![](task4c_zebra_last_conv_activation.png)\n",
    "\n",
    "The activation of the first ten filter in the last convolutional layer of ResNet18.\n",
    "\n",
    "The activation of this layer is abstract, but as the bride spots are shown the model has detected some patterns \n",
    "in the image. Each value does not represent a single pixel but represents a concept like a head, body or leg.\n",
    "Based on these concepts the following fully connected layers can classify the image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (03_Mask_RCNN_matterport)",
   "language": "python",
   "name": "pycharm-a444bf89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}