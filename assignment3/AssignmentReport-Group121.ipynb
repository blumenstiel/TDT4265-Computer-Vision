{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report\n",
    "\n",
    "Group 121 – Etienne Gaucher, Benedikt Blumenstiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "## Task 1a)\n",
    "With zero-padding:\n",
    "\n",
    " 2 | -1 | 11 | -2 | -13\n",
    "---|---|---|---|---\n",
    " 10 | -4 | 8 | 2 | -18\n",
    " 14 | -1 | -1 | 6 | -9\n",
    "\n",
    "## Task 1b)\n",
    "The __\"Max Pooling\"__ Layer reduce the sensitivity to translationial variations due to the combination of multiple pixels.\n",
    "\n",
    "## Task 1c)\n",
    "As the kernel size is 5x5 the padding should be __2__ on each side to get the same shape.\n",
    "\n",
    "## Task 1d)\n",
    "As the size is reduced by 8 (512 - 504) in each dimension the kernel has a shape of __9 x 9__ (8 +1 centered pixel).\n",
    "\n",
    "## Task 1e)\n",
    "Based in the input shape of 504 x 504 the output shape of the pooling layer is __252 x 252__ as the stride of 2 divide the\n",
    "size in each dimension by 2 (504 / 2 = 252).\n",
    "\n",
    "## Task 1f)\n",
    "THe output shape of the second conv layer is __250 x 250__.\n",
    "\n",
    "## Task 1g)\n",
    "\\begin{align*}\n",
    "number\\ of\\ parameters =\\ & number\\ of\\ weights + number\\ of\\ biases\\\\\n",
    "number\\ of\\ parameters =\\ & 3 ∗ 5 ∗ 5 ∗ 32 + 32 +\\\\\n",
    "& 5 ∗ 5 ∗ 32 ∗ 64 + 64 +\\\\\n",
    "& 5 ∗ 5 ∗ 64 ∗ 128 + 128 +\\\\\n",
    "& 2048 ∗ 64 + 64 +\\\\\n",
    "& 64 ∗ 10 + 10\\\\\n",
    "=\\ & 390410\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final training accuracy is 0.75.\n",
    "\n",
    "The final validation accuracy is 0.698.\n",
    "\n",
    "The final test accuracy is 0.698.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Task 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First model:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.1\n",
    "\n",
    "Optimizer = SGD, without momentum\n",
    "\n",
    "Regularization = no\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = RandomHorizontalFlip(p=0.3)\n",
    "\n",
    "---\n",
    "\n",
    "Second model:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "1 | BatchNorm2D | - | -\n",
    "1 | Dropout (p=0.2) | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "2 | BatchNorm2D | - | -\n",
    "2 | Dropout (p=0.2) | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "3 | BatchNorm2D | - | -\n",
    "3 | Dropout (p=0.2) | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "4 | BatchNorm1D | - | -\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.05\n",
    "\n",
    "Optimizer = SGD, without momentum\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = no\n",
    "\n",
    "\n",
    "## Task 3b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model| Train loss | Training accuracy | Validation accuracy | Test accuracy\n",
    "-|-|--|-- | --\n",
    "1 | 0.51 | 0.822 | 0.752 | 0.756\n",
    "2 | 0.17 | 0.950 | 0.797 | 0.796\n",
    "\n",
    "## Task 3c)\n",
    "\n",
    "After having tried all the different tricks to improve our model, we notice batch normalization, data augmentation, dropout, and Adam optimizer are the most useful and effective methods.\n",
    "The network is more efficient with batch normalization since each layer learns independently of the other layers. With data augmentation, the neural network generalizes better because we train our model on different pictures, the model doesn't learn with the same pictures. Similarly, dropout forces the network to more generalize by \"cuting\" connections. Adam optimizer combines advantages of several optimizers.\n",
    "\n",
    "Reducing the filter sizes and the number of filter don't work. The activation function nn.Tanh doesn't improve the model.\n",
    "\n",
    "![](task2c_train_loss.png)\n",
    "\n",
    "\n",
    "## Task 3d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We improve our model to reach an accuracy of at least 80% on the test set within 10 epochs.\n",
    "\n",
    "The model is:\n",
    "\n",
    "Layer | Layer Type | Number of Hidden Units / Filters | Activation Function\n",
    "-|-|--|--\n",
    "1 | Conv2D | 64 | ReLU\n",
    "1 | MaxPool2D | - | -\n",
    "1 | BatchNorm2D | - | -\n",
    "1 | Dropout (p=0.2) | - | -\n",
    "2 | Conv2D | 128 | ReLU\n",
    "2 | MaxPool2D | - | -\n",
    "2 | BatchNorm2D | - | -\n",
    "2 | Dropout (p=0.2) | - | -\n",
    "3 | Conv2D | 128 | ReLU\n",
    "3 | MaxPool2D | - | -\n",
    "3 | BatchNorm2D | - | -\n",
    "3 | Dropout (p=0.2) | - | -\n",
    "  | Flatten | - | -\n",
    "4 | Fully-Connected | 64 | ReLU\n",
    "4 | BatchNorm1D | - | -\n",
    "5 | Fully-Connected | 10 | Softmax\n",
    "\n",
    "Learning rate = 0.1\n",
    "\n",
    "Optimizer = SGD, momentum = 0.7\n",
    "\n",
    "Batch size = 64\n",
    "\n",
    "Data augmentation = RandomHorizontalFlip(p=0.3)\n",
    "\n",
    "We get a test accuracy of 81.2%.\n",
    "<br>\n",
    "<br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4a)\n",
    "![](task4a_transfer_learning.png)\n",
    "\n",
    "The model reached a final validation accuracy of 0.903 with a validation loss of 0.33.\n",
    "\n",
    "Following the advice we choose this hyperparameters:\n",
    "* Adam Optimizer\n",
    "* batch_size = 32\n",
    "* learning_rate = 5e-4\n",
    "* epochs = 5\n",
    "* early_stop_count = 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](task4b_zebra_first_weights.png)\n",
    "![](task4b_zebra_first_activation.png)\n",
    "\n",
    "The ﬁlter weights (top row) and the activation to the corresponding ﬁlter (bottom row) of the ﬁrst\n",
    "convolutional layer in ResNet18 with indices [14, 26, 32, 49, 52].\n",
    "\n",
    "The brighter a area the higher the activation of the filter. The different filter extract different information from the\n",
    "image. For example, the selected filters are detecting the outline of the zebra (14th filter), edges (26th filter) and\n",
    "different colors (49th filter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4c)\n",
    "![](task4c_zebra_last_conv_activation.png)\n",
    "\n",
    "The activation of the first ten filter in the last convolutional layer of ResNet18.\n",
    "\n",
    "The activation of this layer is abstract, but as the bride spots are shown the model has detected some patterns \n",
    "in the image. Each value does not represent a single pixel anymore but represents a concept like a head, body or leg. \n",
    "Based on these concept the following fully connected layers can classify the image. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (03_Mask_RCNN_matterport)",
   "language": "python",
   "name": "pycharm-a444bf89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}