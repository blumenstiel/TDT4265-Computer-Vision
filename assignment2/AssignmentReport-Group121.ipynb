{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report\n",
    "\n",
    "Group 121 â€“ Etienne Gaucher, Benedikt Blumenstiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1a)\n",
    "\n",
    "We first use the chain rule.\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial w_{ji}} = \\sum \\limits_{k} \\frac{\\partial C}{\\partial z_k} \\frac{\\partial z_k}{\\partial a_j}\\frac{\\partial a_j}{\\partial z_j}\\frac{\\partial z_j}{\\partial w_{ji}}$$\n",
    "\n",
    "We have $\\frac{\\partial C}{\\partial z_k} = \\delta_k$ by definition, $\\frac{\\partial z_k}{\\partial a_j} = w_{kj}$, $\\frac{\\partial a_j}{\\partial z_j} = f'(z_j)$ and $\\frac{\\partial z_j}{\\partial w_{ji}} = x_i$.\n",
    "\n",
    "We get\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial w_{ji}} = \\sum \\limits_{k} \\delta_k w_{kj} f'(z_j)x_i =f'(z_j)x_i \\sum \\limits_{k} \\delta_k w_{kj} $$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$w_{ji} = w_{ji} - \\alpha \\frac{\\partial C}{\\partial w_{ji}} = w_{ji} - \\alpha   \\delta_j x_i$$ with $\\delta_j = f'(z_j) \\sum \\limits_{k}  w_{kj} \\delta_k $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b)\n",
    "\n",
    "We refer to $W_2$ as the weight matrix from the hidden layer to the output layer, having a shape of $j \\times k$ with\n",
    "$k$ is the number of output neurons and $j$ the number of hidden neurons. Similar, $W_1$ is the weight matrix from\n",
    "the input layer to the hidden layer with a shape of $j \\times i$, where $i$ is the number of input neurons.\n",
    "$\\alpha$ refers to the learning rate.\n",
    "\n",
    "$\\delta_2$ (shape $j \\times k$) is the gradient between hidden layer and output layer, $\\delta_1$ (shape $j \\times i$)\n",
    "is the gradient between input layer and hidden layer. $x$ is the input vector (length $i$), $y$ the target vector\n",
    "(length $k$) and $o$ the predicted output vector (length $k$). $a$ is the output of the hidden layer (length $j$).\n",
    "\n",
    "$$W_2 = W_2 - \\alpha \\times \\delta_2$$\n",
    "\n",
    "$$W_1 = W_1 - \\alpha \\times \\delta_1$$\n",
    "\n",
    "\n",
    "$$\\delta_2 = (a)^T \\cdot - (y - o)$$\n",
    "\n",
    "$$\\delta_1 = (X)^T \\cdot - (y - o) \\cdot (W_2)^T$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\\begin{align*}\n",
    "\\text{Number of parameter} &= \\text{number of weights + number of biases} \\\\\n",
    "&= 785 \\times 64 + 64 \\times 10 + 0 \\\\\n",
    "&= 50 880\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](task3_combined_comparison.png)\n",
    "\n",
    "We can sort all the methods according to learning speed/convergence speed: model 2 < model with all improvements < model with momentum < model with improved weight initialization < model with improved weight initialization and momentum < model with improved weight initialization and sigmoid.\n",
    "The different methods improve a lot the learning speed, but not so much if we use all the tricks at the same time.\n",
    "\n",
    "We can notice that the use at the same time of improved sigmoid and weight initialization overfit data if we don't stop the learning early enough, because the validation cost improves after a certain number of epoch. It is also the case for the model with improved momentum and all the improvements.\n",
    "\n",
    "Regarding the final accuracy, the model with improved sigmoid and weight initialization has the best score.\n",
    "\n",
    "Therefore, the best model in terms of learning speed and validation loss is the model with improved sigmoid and weight initialization, but we have to include a stronger early stopping if we want to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "![](task4ab_num_hidden_neurons.png)\n",
    "FILL IN ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "FILL IN ANSWER\n",
    "refer to previous plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "We are looking for a number of neurons per hidden layer equal to the same number parameter than the previous model.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Number of parameter} &= \\text{number of weights + number of biases} \\\\\n",
    "50 880 &= 785 \\times x + x \\times + x \\times 10 + 0 \\\\\n",
    "0 &= x^2 + 795x - 50 880\\\\\n",
    "x &= \\frac{795}{2} +   \\sqrt{(\\frac{795}{2})^2 + 50 880}\\\\\n",
    "x &= 59.5407\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, we train the model with two hidden layer with 60 neurons each, resulting in 51 300 parameters.\n",
    "\n",
    "![](task4de_hidden_layers.png)\n",
    "FILL IN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER\n",
    "refer to previous plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}